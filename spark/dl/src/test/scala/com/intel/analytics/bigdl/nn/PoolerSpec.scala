/*
 * Copyright 2016 The BigDL Authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.intel.analytics.bigdl.nn

import org.scalatest.{FlatSpec, Matchers}
import com.intel.analytics.bigdl.tensor.{Storage, Tensor}
import com.intel.analytics.bigdl.utils.{T, Table}

class PoolerSpec extends FlatSpec with Matchers {
  "updateOutput Float type" should "work properly" in {
    val feature1 = Array(0.873747766017913818, 0.145658850669860840,
      0.256294071674346924, 0.280913352966308594, 0.062630355358123779,
      0.272662281990051270, 0.524160504341125488, 0.110454082489013672,
      0.619955241680145264, 0.568557560443878174, 0.214293479919433594,
      0.648296296596527100, 0.165463507175445557, 0.419352889060974121,
      0.852317929267883301, 0.628634154796600342, 0.678495228290557861,
      0.896998584270477295, 0.890723347663879395, 0.488525688648223877,
      0.384370744228363037, 0.571207761764526367, 0.788873314857482910,
      0.954643964767456055, 0.969983577728271484, 0.203537940979003906,
      0.782353222370147705, 0.848326086997985840, 0.304318606853485107,
      0.800064325332641602, 0.424848318099975586, 0.603751122951507568,
      0.864419877529144287, 0.702363312244415283, 0.570423781871795654,
      0.409119188785552979, 0.400403201580047607, 0.526863992214202881,
      0.016368329524993896, 0.764127612113952637, 0.103974938392639160,
      0.372822880744934082, 0.033449709415435791, 0.515862822532653809,
      0.897693097591400146, 0.253236830234527588, 0.715021133422851562,
      0.795187711715698242, 0.532655417919158936, 0.605576932430267334,
      0.314174890518188477, 0.113613069057464600, 0.077841997146606445,
      0.381529927253723145, 0.485041558742523193, 0.588989436626434326,
      0.185753941535949707, 0.918586552143096924, 0.657631874084472656,
      0.800176382064819336, 0.658552944660186768, 0.561446070671081543,
      0.698397099971771240, 0.739861011505126953)

    val feature2 = Array(
      0.023863613605499268, 0.100520193576812744, 0.579659581184387207,
      0.491799056529998779, 0.695049762725830078, 0.174113810062408447,
      0.514802277088165283, 0.645381748676300049, 0.610754907131195068,
      0.642783403396606445, 0.261436760425567627, 0.865309834480285645,
      0.779586195945739746, 0.805720150470733643, 0.039021611213684082,
      0.052066206932067871, 0.859684348106384277, 0.286012887954711914,
      0.183007895946502686, 0.657920598983764648, 0.486495614051818848,
      0.339991390705108643, 0.349600136280059814, 0.292829811573028564,
      0.874850273132324219, 0.923728287220001221, 0.853209257125854492,
      0.078126728534698486, 0.975298523902893066, 0.889039456844329834,
      0.757552802562713623, 0.009770631790161133, 0.639949500560760498,
      0.384162366390228271, 0.993775784969329834, 0.225636243820190430,
      0.152042329311370850, 0.518522977828979492, 0.346138358116149902,
      0.560805261135101318, 0.197446644306182861, 0.270632088184356689,
      0.537619173526763916, 0.282237291336059570, 0.418838739395141602,
      0.348786175251007080, 0.827486872673034668, 0.671141088008880615,
      0.734223365783691406, 0.461709976196289062, 0.463822364807128906,
      0.256826639175415039, 0.187998294830322266, 0.387186825275421143,
      0.027970135211944580, 0.336534321308135986, 0.078408479690551758,
      0.748133420944213867, 0.996697187423706055, 0.590924799442291260,
      0.363863050937652588, 0.244512259960174561, 0.605456709861755371,
      0.989919960498809814, 0.998104333877563477, 0.318823933601379395,
      0.293298780918121338, 0.240437865257263184, 0.269145488739013672,
      0.321916043758392334, 0.241542100906372070, 0.097301602363586426,
      0.139740049839019775, 0.727295756340026855, 0.735020518302917480,
      0.977046966552734375, 0.562069535255432129, 0.962157845497131348,
      0.896494269371032715, 0.919544279575347900, 0.769982337951660156,
      0.902598083019256592, 0.699079096317291260, 0.970299720764160156,
      0.877977848052978516, 0.445257008075714111, 0.903108179569244385,
      0.029258608818054199, 0.953712522983551025, 0.740538537502288818,
      0.229142010211944580, 0.324616789817810059, 0.546005189418792725,
      0.471910834312438965, 0.479964077472686768, 0.404208302497863770,
      0.816056787967681885, 0.116290867328643799, 0.845461726188659668,
      0.313867926597595215, 0.281320571899414062, 0.693770170211791992,
      0.623112499713897705, 0.370123684406280518, 0.595665276050567627,
      0.433298051357269287, 0.971214890480041504, 0.087709188461303711,
      0.069373369216918945, 0.274347186088562012, 0.470574259757995605,
      0.883642554283142090, 0.518250524997711182, 0.118440926074981689,
      0.606658637523651123, 0.529120385646820068, 0.991135418415069580,
      0.020969033241271973, 0.601271688938140869, 0.031737148761749268,
      0.699844896793365479, 0.006896257400512695, 0.478346049785614014,
      0.267558634281158447, 0.762180626392364502, 0.907826840877532959,
      0.316000878810882568, 0.405982732772827148, 0.952247321605682373,
      0.621758222579956055, 0.984782218933105469, 0.855552852153778076,
      0.853232085704803467, 0.108074665069580078, 0.136160314083099365,
      0.699587583541870117, 0.455291092395782471, 0.339040815830230713,
      0.195561707019805908, 0.744465529918670654, 0.839737772941589355,
      0.121415317058563232, 0.609103679656982422, 0.751573920249938965,
      0.100943267345428467, 0.609663605690002441, 0.552886843681335449,
      0.530253231525421143, 0.535715997219085693, 0.386290609836578369,
      0.566541373729705811, 0.109940528869628906, 0.040631473064422607,
      0.383415877819061279, 0.420698642730712891, 0.486727476119995117,
      0.316030442714691162, 0.399610400199890137, 0.822746813297271729,
      0.615983247756958008, 0.698890924453735352, 0.602992057800292969,
      0.731686592102050781, 0.765341222286224365, 0.943145513534545898,
      0.663275897502899170, 0.658695399761199951, 0.270870804786682129,
      0.708790242671966553, 0.514617204666137695, 0.562473952770233154,
      0.904682397842407227, 0.882524847984313965, 0.548244178295135498,
      0.734199821949005127, 0.500540435314178467, 0.026508867740631104,
      0.823588609695434570, 0.524205684661865234, 0.332086920738220215,
      0.660677015781402588, 0.006234705448150635, 0.402668416500091553,
      0.605218589305877686, 0.517469227313995361, 0.173339605331420898,
      0.287992835044860840, 0.028889238834381104, 0.423897266387939453,
      0.179210901260375977, 0.907838046550750732, 0.710119545459747314,
      0.037721812725067139, 0.287807941436767578, 0.386206328868865967,
      0.884501159191131592, 0.520467817783355713, 0.014881670475006104,
      0.683837294578552246, 0.644677221775054932, 0.659515738487243652,
      0.726319670677185059, 0.456707894802093506, 0.722546756267547607,
      0.378548145294189453, 0.112222671508789062, 0.967624962329864502,
      0.926407516002655029, 0.897468805313110352, 0.931972980499267578,
      0.568775236606597900, 0.344420194625854492, 0.631682753562927246,
      0.002464890480041504, 0.963871061801910400, 0.476610541343688965,
      0.996321439743041992, 0.499588489532470703, 0.635297894477844238,
      0.802769958972930908, 0.734768807888031006, 0.656373441219329834,
      0.812671184539794922, 0.526163458824157715, 0.415958523750305176,
      0.527178049087524414, 0.580165207386016846, 0.920745611190795898,
      0.193983256816864014, 0.661489725112915039, 0.712282001972198486,
      0.882635891437530518, 0.486002802848815918, 0.077735543251037598,
      0.656417191028594971, 0.437246561050415039, 0.057095408439636230,
      0.921051084995269775, 0.468123137950897217, 0.402775049209594727,
      0.757351040840148926, 0.501314222812652588, 0.360828220844268799,
      0.734019339084625244, 0.081997990608215332, 0.274612605571746826,
      0.711006700992584229, 0.546012401580810547, 0.163319110870361328,
      0.804031491279602051, 0.870508790016174316, 0.896108865737915039,
      0.296806037425994873, 0.231733143329620361, 0.102892518043518066,
      0.652749657630920410)

    val features = new Table()
    features.insert(Tensor(Storage(feature1.map(x => x.toFloat))).resize(2, 2, 4, 4))
    features.insert(Tensor(Storage(feature2.map(x => x.toFloat))).resize(2, 2, 8, 8))
    val rois = Tensor[Float](T(0, 0, 0, 3, 3)).resize(1, 5)
    val input = T(features, rois)

    val pooler = Pooler[Float](resolution = 2, scales = Array(1.0f, 0.5f), samplingRatio = 2)
    val res = pooler.forward(input)
    val expectedRes = Array(
      0.293152749538421631, 0.340563237667083740,
      0.480180501937866211, 0.492284327745437622,
      0.617818892002105713, 0.804041504859924316,
      0.526698172092437744, 0.688502669334411621)

    for (i <- expectedRes.indices) {
      assert(Math.abs(res.storage().array()(i) - expectedRes(i)) < 1e-6)
    }
  }

  "updateOutput Double type" should "work properly" in {
    val feature1 = Array(0.873747766017913818, 0.145658850669860840,
      0.256294071674346924, 0.280913352966308594, 0.062630355358123779,
      0.272662281990051270, 0.524160504341125488, 0.110454082489013672,
      0.619955241680145264, 0.568557560443878174, 0.214293479919433594,
      0.648296296596527100, 0.165463507175445557, 0.419352889060974121,
      0.852317929267883301, 0.628634154796600342, 0.678495228290557861,
      0.896998584270477295, 0.890723347663879395, 0.488525688648223877,
      0.384370744228363037, 0.571207761764526367, 0.788873314857482910,
      0.954643964767456055, 0.969983577728271484, 0.203537940979003906,
      0.782353222370147705, 0.848326086997985840, 0.304318606853485107,
      0.800064325332641602, 0.424848318099975586, 0.603751122951507568,
      0.864419877529144287, 0.702363312244415283, 0.570423781871795654,
      0.409119188785552979, 0.400403201580047607, 0.526863992214202881,
      0.016368329524993896, 0.764127612113952637, 0.103974938392639160,
      0.372822880744934082, 0.033449709415435791, 0.515862822532653809,
      0.897693097591400146, 0.253236830234527588, 0.715021133422851562,
      0.795187711715698242, 0.532655417919158936, 0.605576932430267334,
      0.314174890518188477, 0.113613069057464600, 0.077841997146606445,
      0.381529927253723145, 0.485041558742523193, 0.588989436626434326,
      0.185753941535949707, 0.918586552143096924, 0.657631874084472656,
      0.800176382064819336, 0.658552944660186768, 0.561446070671081543,
      0.698397099971771240, 0.739861011505126953)

    val feature2 = Array(
      0.023863613605499268, 0.100520193576812744, 0.579659581184387207,
      0.491799056529998779, 0.695049762725830078, 0.174113810062408447,
      0.514802277088165283, 0.645381748676300049, 0.610754907131195068,
      0.642783403396606445, 0.261436760425567627, 0.865309834480285645,
      0.779586195945739746, 0.805720150470733643, 0.039021611213684082,
      0.052066206932067871, 0.859684348106384277, 0.286012887954711914,
      0.183007895946502686, 0.657920598983764648, 0.486495614051818848,
      0.339991390705108643, 0.349600136280059814, 0.292829811573028564,
      0.874850273132324219, 0.923728287220001221, 0.853209257125854492,
      0.078126728534698486, 0.975298523902893066, 0.889039456844329834,
      0.757552802562713623, 0.009770631790161133, 0.639949500560760498,
      0.384162366390228271, 0.993775784969329834, 0.225636243820190430,
      0.152042329311370850, 0.518522977828979492, 0.346138358116149902,
      0.560805261135101318, 0.197446644306182861, 0.270632088184356689,
      0.537619173526763916, 0.282237291336059570, 0.418838739395141602,
      0.348786175251007080, 0.827486872673034668, 0.671141088008880615,
      0.734223365783691406, 0.461709976196289062, 0.463822364807128906,
      0.256826639175415039, 0.187998294830322266, 0.387186825275421143,
      0.027970135211944580, 0.336534321308135986, 0.078408479690551758,
      0.748133420944213867, 0.996697187423706055, 0.590924799442291260,
      0.363863050937652588, 0.244512259960174561, 0.605456709861755371,
      0.989919960498809814, 0.998104333877563477, 0.318823933601379395,
      0.293298780918121338, 0.240437865257263184, 0.269145488739013672,
      0.321916043758392334, 0.241542100906372070, 0.097301602363586426,
      0.139740049839019775, 0.727295756340026855, 0.735020518302917480,
      0.977046966552734375, 0.562069535255432129, 0.962157845497131348,
      0.896494269371032715, 0.919544279575347900, 0.769982337951660156,
      0.902598083019256592, 0.699079096317291260, 0.970299720764160156,
      0.877977848052978516, 0.445257008075714111, 0.903108179569244385,
      0.029258608818054199, 0.953712522983551025, 0.740538537502288818,
      0.229142010211944580, 0.324616789817810059, 0.546005189418792725,
      0.471910834312438965, 0.479964077472686768, 0.404208302497863770,
      0.816056787967681885, 0.116290867328643799, 0.845461726188659668,
      0.313867926597595215, 0.281320571899414062, 0.693770170211791992,
      0.623112499713897705, 0.370123684406280518, 0.595665276050567627,
      0.433298051357269287, 0.971214890480041504, 0.087709188461303711,
      0.069373369216918945, 0.274347186088562012, 0.470574259757995605,
      0.883642554283142090, 0.518250524997711182, 0.118440926074981689,
      0.606658637523651123, 0.529120385646820068, 0.991135418415069580,
      0.020969033241271973, 0.601271688938140869, 0.031737148761749268,
      0.699844896793365479, 0.006896257400512695, 0.478346049785614014,
      0.267558634281158447, 0.762180626392364502, 0.907826840877532959,
      0.316000878810882568, 0.405982732772827148, 0.952247321605682373,
      0.621758222579956055, 0.984782218933105469, 0.855552852153778076,
      0.853232085704803467, 0.108074665069580078, 0.136160314083099365,
      0.699587583541870117, 0.455291092395782471, 0.339040815830230713,
      0.195561707019805908, 0.744465529918670654, 0.839737772941589355,
      0.121415317058563232, 0.609103679656982422, 0.751573920249938965,
      0.100943267345428467, 0.609663605690002441, 0.552886843681335449,
      0.530253231525421143, 0.535715997219085693, 0.386290609836578369,
      0.566541373729705811, 0.109940528869628906, 0.040631473064422607,
      0.383415877819061279, 0.420698642730712891, 0.486727476119995117,
      0.316030442714691162, 0.399610400199890137, 0.822746813297271729,
      0.615983247756958008, 0.698890924453735352, 0.602992057800292969,
      0.731686592102050781, 0.765341222286224365, 0.943145513534545898,
      0.663275897502899170, 0.658695399761199951, 0.270870804786682129,
      0.708790242671966553, 0.514617204666137695, 0.562473952770233154,
      0.904682397842407227, 0.882524847984313965, 0.548244178295135498,
      0.734199821949005127, 0.500540435314178467, 0.026508867740631104,
      0.823588609695434570, 0.524205684661865234, 0.332086920738220215,
      0.660677015781402588, 0.006234705448150635, 0.402668416500091553,
      0.605218589305877686, 0.517469227313995361, 0.173339605331420898,
      0.287992835044860840, 0.028889238834381104, 0.423897266387939453,
      0.179210901260375977, 0.907838046550750732, 0.710119545459747314,
      0.037721812725067139, 0.287807941436767578, 0.386206328868865967,
      0.884501159191131592, 0.520467817783355713, 0.014881670475006104,
      0.683837294578552246, 0.644677221775054932, 0.659515738487243652,
      0.726319670677185059, 0.456707894802093506, 0.722546756267547607,
      0.378548145294189453, 0.112222671508789062, 0.967624962329864502,
      0.926407516002655029, 0.897468805313110352, 0.931972980499267578,
      0.568775236606597900, 0.344420194625854492, 0.631682753562927246,
      0.002464890480041504, 0.963871061801910400, 0.476610541343688965,
      0.996321439743041992, 0.499588489532470703, 0.635297894477844238,
      0.802769958972930908, 0.734768807888031006, 0.656373441219329834,
      0.812671184539794922, 0.526163458824157715, 0.415958523750305176,
      0.527178049087524414, 0.580165207386016846, 0.920745611190795898,
      0.193983256816864014, 0.661489725112915039, 0.712282001972198486,
      0.882635891437530518, 0.486002802848815918, 0.077735543251037598,
      0.656417191028594971, 0.437246561050415039, 0.057095408439636230,
      0.921051084995269775, 0.468123137950897217, 0.402775049209594727,
      0.757351040840148926, 0.501314222812652588, 0.360828220844268799,
      0.734019339084625244, 0.081997990608215332, 0.274612605571746826,
      0.711006700992584229, 0.546012401580810547, 0.163319110870361328,
      0.804031491279602051, 0.870508790016174316, 0.896108865737915039,
      0.296806037425994873, 0.231733143329620361, 0.102892518043518066,
      0.652749657630920410)

    val features = new Table()
    features.insert(Tensor(Storage(feature1.map(x => x.toDouble))).resize(2, 2, 4, 4))
    features.insert(Tensor(Storage(feature2.map(x => x.toDouble))).resize(2, 2, 8, 8))
    val rois = Tensor[Double](T(0, 0, 0, 3, 3)).resize(1, 5)
    val input = T(features, rois)

    val pooler = Pooler[Double](resolution = 2, scales = Array(1.0, 0.5), samplingRatio = 2)

    val res = pooler.forward(input)
    val expectedRes = Array(
      0.293152749538421631, 0.340563237667083740,
      0.480180501937866211, 0.492284327745437622,
      0.617818892002105713, 0.804041504859924316,
      0.526698172092437744, 0.688502669334411621)

    for (i <- expectedRes.indices) {
      assert(Math.abs(res.storage().array()(i) - expectedRes(i)) < 1e-6)
    }
  }
}
